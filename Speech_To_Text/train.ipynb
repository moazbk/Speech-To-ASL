{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\EAGLE\\Anaconda3\\envs\\g2\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "Saving vectors of label - 'a': 100%|██████████| 23/23 [00:00<00:00, 112.19it/s]\n",
      "Saving vectors of label - 'about': 100%|██████| 33/33 [00:00<00:00, 109.99it/s]\n",
      "Saving vectors of label - 'be': 100%|█████████| 36/36 [00:00<00:00, 112.42it/s]\n",
      "Saving vectors of label - 'complete': 100%|███| 40/40 [00:00<00:00, 113.63it/s]\n",
      "Saving vectors of label - 'e-learning': 100%|█| 30/30 [00:00<00:00, 109.48it/s]\n",
      "Saving vectors of label - 'from': 100%|███████| 39/39 [00:00<00:00, 116.06it/s]\n",
      "Saving vectors of label - 'how': 100%|█████████| 39/39 [00:00<00:00, 96.77it/s]\n",
      "Saving vectors of label - 'internet': 100%|████| 52/52 [00:00<00:00, 94.89it/s]\n",
      "Saving vectors of label - 'is': 100%|██████████| 54/54 [00:00<00:00, 97.29it/s]\n",
      "Saving vectors of label - 'issues': 100%|██████| 31/31 [00:00<00:00, 94.80it/s]\n",
      "Saving vectors of label - 'lecture': 100%|████| 45/45 [00:00<00:00, 109.22it/s]\n",
      "Saving vectors of label - 'major': 100%|██████| 38/38 [00:00<00:00, 100.52it/s]\n",
      "Saving vectors of label - 'on': 100%|█████████| 39/39 [00:00<00:00, 107.14it/s]\n",
      "Saving vectors of label - 'Recognition': 100%|█| 44/44 [00:00<00:00, 103.28it/s]\n",
      "Saving vectors of label - 'security': 100%|████| 32/32 [00:00<00:00, 99.68it/s]\n",
      "Saving vectors of label - 'Speech': 100%|█████| 26/26 [00:00<00:00, 107.43it/s]\n",
      "Saving vectors of label - 'submission': 100%|█| 40/40 [00:00<00:00, 104.43it/s]\n",
      "Saving vectors of label - 'suffers': 100%|█████| 29/29 [00:00<00:00, 81.69it/s]\n",
      "Saving vectors of label - 'the': 100%|████████| 44/44 [00:00<00:00, 108.64it/s]\n",
      "Saving vectors of label - 'there': 100%|██████| 46/46 [00:00<00:00, 109.39it/s]\n",
      "Saving vectors of label - 'today': 100%|██████| 46/46 [00:00<00:00, 112.19it/s]\n",
      "Saving vectors of label - 'will': 100%|███████| 49/49 [00:00<00:00, 112.64it/s]\n",
      "Saving vectors of label - 'works': 100%|██████| 61/61 [00:00<00:00, 107.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'be', 'complete', 'e-learning', 'from', 'how', 'internet', 'is', 'issues', 'lecture', 'major', 'on', 'Recognition', 'security', 'Speech', 'submission', 'suffers', 'the', 'there', 'today', 'will', 'works']\n",
      "WARNING:tensorflow:From C:\\Users\\EAGLE\\Anaconda3\\envs\\g2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\EAGLE\\Anaconda3\\envs\\g2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\EAGLE\\Anaconda3\\envs\\g2\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 641 samples, validate on 275 samples\n",
      "Epoch 1/30\n",
      "641/641 [==============================] - ETA: 10s - loss: 7.2363 - acc: 0.02 - ETA: 5s - loss: 5.8093 - acc: 0.0250 - ETA: 3s - loss: 5.1847 - acc: 0.020 - ETA: 2s - loss: 4.6805 - acc: 0.043 - ETA: 1s - loss: 4.3881 - acc: 0.037 - ETA: 0s - loss: 4.1768 - acc: 0.058 - ETA: 0s - loss: 4.0426 - acc: 0.057 - ETA: 0s - loss: 3.9278 - acc: 0.054 - 3s 5ms/step - loss: 3.9263 - acc: 0.0546 - val_loss: 2.9638 - val_acc: 0.0655\n",
      "Epoch 2/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 3.2505 - acc: 0.100 - ETA: 1s - loss: 3.1323 - acc: 0.125 - ETA: 0s - loss: 3.1246 - acc: 0.104 - ETA: 0s - loss: 3.0592 - acc: 0.121 - ETA: 0s - loss: 3.0870 - acc: 0.120 - ETA: 0s - loss: 3.0261 - acc: 0.135 - ETA: 0s - loss: 2.9811 - acc: 0.144 - ETA: 0s - loss: 2.9444 - acc: 0.145 - 2s 3ms/step - loss: 2.9465 - acc: 0.1451 - val_loss: 2.6764 - val_acc: 0.2400\n",
      "Epoch 3/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 3.0822 - acc: 0.150 - ETA: 1s - loss: 3.0353 - acc: 0.125 - ETA: 0s - loss: 2.9355 - acc: 0.137 - ETA: 0s - loss: 2.9099 - acc: 0.146 - ETA: 0s - loss: 2.8480 - acc: 0.162 - ETA: 0s - loss: 2.8230 - acc: 0.164 - ETA: 0s - loss: 2.7846 - acc: 0.178 - ETA: 0s - loss: 2.7564 - acc: 0.181 - 2s 3ms/step - loss: 2.7541 - acc: 0.1825 - val_loss: 2.4626 - val_acc: 0.1236\n",
      "Epoch 4/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 2.9394 - acc: 0.162 - ETA: 1s - loss: 2.7600 - acc: 0.175 - ETA: 0s - loss: 2.5988 - acc: 0.212 - ETA: 0s - loss: 2.4819 - acc: 0.240 - ETA: 0s - loss: 2.4824 - acc: 0.255 - ETA: 0s - loss: 2.4812 - acc: 0.262 - ETA: 0s - loss: 2.4365 - acc: 0.275 - ETA: 0s - loss: 2.4018 - acc: 0.281 - 2s 3ms/step - loss: 2.4014 - acc: 0.2808 - val_loss: 2.1809 - val_acc: 0.2764\n",
      "Epoch 5/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 2.9005 - acc: 0.225 - ETA: 1s - loss: 2.5606 - acc: 0.281 - ETA: 1s - loss: 2.3842 - acc: 0.333 - ETA: 0s - loss: 2.3187 - acc: 0.340 - ETA: 0s - loss: 2.3051 - acc: 0.345 - ETA: 0s - loss: 2.2530 - acc: 0.345 - ETA: 0s - loss: 2.1802 - acc: 0.360 - ETA: 0s - loss: 2.1328 - acc: 0.371 - 2s 3ms/step - loss: 2.1324 - acc: 0.3713 - val_loss: 2.1756 - val_acc: 0.3345\n",
      "Epoch 6/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 3.0803 - acc: 0.175 - ETA: 1s - loss: 2.5261 - acc: 0.293 - ETA: 0s - loss: 2.3360 - acc: 0.320 - ETA: 0s - loss: 2.1692 - acc: 0.368 - ETA: 0s - loss: 2.0967 - acc: 0.367 - ETA: 0s - loss: 1.9871 - acc: 0.404 - ETA: 0s - loss: 1.9452 - acc: 0.416 - ETA: 0s - loss: 1.9090 - acc: 0.429 - 2s 3ms/step - loss: 1.9061 - acc: 0.4306 - val_loss: 1.0469 - val_acc: 0.7709\n",
      "Epoch 7/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 1.5505 - acc: 0.562 - ETA: 1s - loss: 1.5137 - acc: 0.575 - ETA: 0s - loss: 1.5350 - acc: 0.579 - ETA: 0s - loss: 1.5051 - acc: 0.565 - ETA: 0s - loss: 1.4186 - acc: 0.590 - ETA: 0s - loss: 1.3986 - acc: 0.595 - ETA: 0s - loss: 1.4251 - acc: 0.589 - ETA: 0s - loss: 1.5033 - acc: 0.579 - 2s 3ms/step - loss: 1.5047 - acc: 0.5788 - val_loss: 1.4567 - val_acc: 0.6327\n",
      "Epoch 8/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 2.2098 - acc: 0.425 - ETA: 1s - loss: 1.8302 - acc: 0.493 - ETA: 1s - loss: 1.6937 - acc: 0.525 - ETA: 0s - loss: 1.6127 - acc: 0.543 - ETA: 0s - loss: 1.5034 - acc: 0.570 - ETA: 0s - loss: 1.5069 - acc: 0.562 - ETA: 0s - loss: 1.4658 - acc: 0.566 - ETA: 0s - loss: 1.4455 - acc: 0.578 - 2s 3ms/step - loss: 1.4481 - acc: 0.5772 - val_loss: 1.7101 - val_acc: 0.5345\n",
      "Epoch 9/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 2.2371 - acc: 0.387 - ETA: 1s - loss: 1.9400 - acc: 0.431 - ETA: 0s - loss: 1.6921 - acc: 0.504 - ETA: 0s - loss: 1.6097 - acc: 0.525 - ETA: 0s - loss: 1.5648 - acc: 0.537 - ETA: 0s - loss: 1.5107 - acc: 0.556 - ETA: 0s - loss: 1.4437 - acc: 0.582 - ETA: 0s - loss: 1.3761 - acc: 0.600 - 2s 3ms/step - loss: 1.3765 - acc: 0.6006 - val_loss: 0.7731 - val_acc: 0.8218\n",
      "Epoch 10/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 1.6059 - acc: 0.462 - ETA: 1s - loss: 1.4287 - acc: 0.518 - ETA: 1s - loss: 1.3876 - acc: 0.529 - ETA: 0s - loss: 1.3297 - acc: 0.559 - ETA: 0s - loss: 1.2861 - acc: 0.582 - ETA: 0s - loss: 1.2012 - acc: 0.616 - ETA: 0s - loss: 1.1884 - acc: 0.621 - ETA: 0s - loss: 1.1958 - acc: 0.617 - 2s 3ms/step - loss: 1.1939 - acc: 0.6178 - val_loss: 0.4929 - val_acc: 0.9055\n",
      "Epoch 11/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 1.0495 - acc: 0.712 - ETA: 1s - loss: 0.8685 - acc: 0.762 - ETA: 0s - loss: 0.8806 - acc: 0.754 - ETA: 0s - loss: 0.9111 - acc: 0.734 - ETA: 0s - loss: 0.8858 - acc: 0.740 - ETA: 0s - loss: 0.8569 - acc: 0.741 - ETA: 0s - loss: 0.8372 - acc: 0.742 - ETA: 0s - loss: 0.8190 - acc: 0.751 - 2s 3ms/step - loss: 0.8199 - acc: 0.7504 - val_loss: 0.9955 - val_acc: 0.6909\n",
      "Epoch 12/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 1.5024 - acc: 0.512 - ETA: 1s - loss: 1.1501 - acc: 0.637 - ETA: 1s - loss: 1.0837 - acc: 0.658 - ETA: 0s - loss: 0.9702 - acc: 0.690 - ETA: 0s - loss: 0.9425 - acc: 0.695 - ETA: 0s - loss: 0.8981 - acc: 0.712 - ETA: 0s - loss: 0.8719 - acc: 0.721 - ETA: 0s - loss: 0.8849 - acc: 0.717 - 2s 3ms/step - loss: 0.8836 - acc: 0.7176 - val_loss: 0.3195 - val_acc: 0.9164\n",
      "Epoch 13/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.7809 - acc: 0.737 - ETA: 1s - loss: 0.6986 - acc: 0.762 - ETA: 0s - loss: 0.6903 - acc: 0.775 - ETA: 0s - loss: 0.7402 - acc: 0.771 - ETA: 0s - loss: 0.8027 - acc: 0.750 - ETA: 0s - loss: 0.7915 - acc: 0.747 - ETA: 0s - loss: 0.7574 - acc: 0.757 - ETA: 0s - loss: 0.7545 - acc: 0.764 - 2s 3ms/step - loss: 0.7596 - acc: 0.7629 - val_loss: 0.7949 - val_acc: 0.7600\n",
      "Epoch 14/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 1.3135 - acc: 0.537 - ETA: 1s - loss: 1.0538 - acc: 0.656 - ETA: 0s - loss: 0.9518 - acc: 0.704 - ETA: 0s - loss: 0.8991 - acc: 0.731 - ETA: 0s - loss: 0.8519 - acc: 0.740 - ETA: 0s - loss: 0.8202 - acc: 0.754 - ETA: 0s - loss: 0.8301 - acc: 0.748 - ETA: 0s - loss: 0.7885 - acc: 0.759 - 2s 3ms/step - loss: 0.7876 - acc: 0.7598 - val_loss: 0.2712 - val_acc: 0.9345\n",
      "Epoch 15/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.6319 - acc: 0.787 - ETA: 1s - loss: 0.6664 - acc: 0.787 - ETA: 1s - loss: 0.6364 - acc: 0.800 - ETA: 0s - loss: 0.6018 - acc: 0.806 - ETA: 0s - loss: 0.6043 - acc: 0.812 - ETA: 0s - loss: 0.5707 - acc: 0.818 - ETA: 0s - loss: 0.5460 - acc: 0.830 - ETA: 0s - loss: 0.5661 - acc: 0.821 - 2s 3ms/step - loss: 0.5653 - acc: 0.8222 - val_loss: 0.2278 - val_acc: 0.9455\n",
      "Epoch 16/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.5559 - acc: 0.850 - ETA: 1s - loss: 0.4666 - acc: 0.887 - ETA: 1s - loss: 0.4960 - acc: 0.866 - ETA: 0s - loss: 0.4626 - acc: 0.868 - ETA: 0s - loss: 0.4821 - acc: 0.862 - ETA: 0s - loss: 0.4777 - acc: 0.864 - ETA: 0s - loss: 0.4952 - acc: 0.853 - ETA: 0s - loss: 0.5073 - acc: 0.845 - 2s 3ms/step - loss: 0.5065 - acc: 0.8456 - val_loss: 0.2032 - val_acc: 0.9418\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641/641 [==============================] - ETA: 1s - loss: 0.4353 - acc: 0.887 - ETA: 1s - loss: 0.4837 - acc: 0.850 - ETA: 0s - loss: 0.4558 - acc: 0.862 - ETA: 0s - loss: 0.4431 - acc: 0.859 - ETA: 0s - loss: 0.4701 - acc: 0.860 - ETA: 0s - loss: 0.4682 - acc: 0.852 - ETA: 0s - loss: 0.4697 - acc: 0.851 - ETA: 0s - loss: 0.4556 - acc: 0.859 - 2s 3ms/step - loss: 0.4550 - acc: 0.8596 - val_loss: 0.1786 - val_acc: 0.9527\n",
      "Epoch 18/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.3487 - acc: 0.875 - ETA: 1s - loss: 0.3553 - acc: 0.881 - ETA: 0s - loss: 0.4070 - acc: 0.866 - ETA: 0s - loss: 0.4012 - acc: 0.871 - ETA: 0s - loss: 0.4155 - acc: 0.872 - ETA: 0s - loss: 0.4302 - acc: 0.864 - ETA: 0s - loss: 0.4165 - acc: 0.866 - ETA: 0s - loss: 0.4144 - acc: 0.868 - 2s 3ms/step - loss: 0.4138 - acc: 0.8690 - val_loss: 0.1794 - val_acc: 0.9491\n",
      "Epoch 19/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.5912 - acc: 0.800 - ETA: 1s - loss: 0.5272 - acc: 0.831 - ETA: 0s - loss: 0.4688 - acc: 0.850 - ETA: 0s - loss: 0.4488 - acc: 0.865 - ETA: 0s - loss: 0.4797 - acc: 0.860 - ETA: 0s - loss: 0.4781 - acc: 0.860 - ETA: 0s - loss: 0.4612 - acc: 0.866 - ETA: 0s - loss: 0.4364 - acc: 0.868 - 2s 3ms/step - loss: 0.4358 - acc: 0.8690 - val_loss: 0.1301 - val_acc: 0.9673\n",
      "Epoch 20/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.3977 - acc: 0.887 - ETA: 1s - loss: 0.3552 - acc: 0.887 - ETA: 0s - loss: 0.3524 - acc: 0.875 - ETA: 0s - loss: 0.3560 - acc: 0.875 - ETA: 0s - loss: 0.3372 - acc: 0.882 - ETA: 0s - loss: 0.3530 - acc: 0.883 - ETA: 0s - loss: 0.3445 - acc: 0.885 - ETA: 0s - loss: 0.3401 - acc: 0.884 - 2s 3ms/step - loss: 0.3396 - acc: 0.8846 - val_loss: 0.1173 - val_acc: 0.9709\n",
      "Epoch 21/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.2808 - acc: 0.912 - ETA: 1s - loss: 0.3262 - acc: 0.881 - ETA: 0s - loss: 0.3391 - acc: 0.875 - ETA: 0s - loss: 0.3168 - acc: 0.893 - ETA: 0s - loss: 0.3189 - acc: 0.892 - ETA: 0s - loss: 0.3100 - acc: 0.895 - ETA: 0s - loss: 0.2989 - acc: 0.901 - ETA: 0s - loss: 0.3017 - acc: 0.900 - 2s 3ms/step - loss: 0.3013 - acc: 0.9002 - val_loss: 0.1330 - val_acc: 0.9527\n",
      "Epoch 22/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.2376 - acc: 0.900 - ETA: 1s - loss: 0.2925 - acc: 0.900 - ETA: 0s - loss: 0.2648 - acc: 0.920 - ETA: 0s - loss: 0.2815 - acc: 0.912 - ETA: 0s - loss: 0.2856 - acc: 0.912 - ETA: 0s - loss: 0.2858 - acc: 0.914 - ETA: 0s - loss: 0.2721 - acc: 0.921 - ETA: 0s - loss: 0.2725 - acc: 0.914 - 2s 3ms/step - loss: 0.2721 - acc: 0.9142 - val_loss: 0.1151 - val_acc: 0.9636\n",
      "Epoch 23/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.2872 - acc: 0.900 - ETA: 1s - loss: 0.2412 - acc: 0.918 - ETA: 0s - loss: 0.2095 - acc: 0.933 - ETA: 0s - loss: 0.1943 - acc: 0.937 - ETA: 0s - loss: 0.2071 - acc: 0.937 - ETA: 0s - loss: 0.2203 - acc: 0.931 - ETA: 0s - loss: 0.2360 - acc: 0.925 - ETA: 0s - loss: 0.2702 - acc: 0.914 - 2s 3ms/step - loss: 0.2698 - acc: 0.9142 - val_loss: 0.1133 - val_acc: 0.9600\n",
      "Epoch 24/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.2902 - acc: 0.900 - ETA: 1s - loss: 0.3928 - acc: 0.887 - ETA: 0s - loss: 0.3670 - acc: 0.895 - ETA: 0s - loss: 0.3073 - acc: 0.915 - ETA: 0s - loss: 0.2936 - acc: 0.920 - ETA: 0s - loss: 0.2824 - acc: 0.927 - ETA: 0s - loss: 0.2630 - acc: 0.932 - ETA: 0s - loss: 0.2532 - acc: 0.932 - 2s 3ms/step - loss: 0.2533 - acc: 0.9329 - val_loss: 0.4809 - val_acc: 0.8945\n",
      "Epoch 25/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.6134 - acc: 0.800 - ETA: 1s - loss: 0.4532 - acc: 0.843 - ETA: 0s - loss: 0.3534 - acc: 0.875 - ETA: 0s - loss: 0.3312 - acc: 0.875 - ETA: 0s - loss: 0.3325 - acc: 0.877 - ETA: 0s - loss: 0.3429 - acc: 0.877 - ETA: 0s - loss: 0.3397 - acc: 0.876 - ETA: 0s - loss: 0.3449 - acc: 0.878 - 2s 3ms/step - loss: 0.3443 - acc: 0.8783 - val_loss: 0.0894 - val_acc: 0.9709\n",
      "Epoch 26/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.1563 - acc: 0.962 - ETA: 1s - loss: 0.1755 - acc: 0.956 - ETA: 0s - loss: 0.1866 - acc: 0.950 - ETA: 0s - loss: 0.2175 - acc: 0.937 - ETA: 0s - loss: 0.2324 - acc: 0.927 - ETA: 0s - loss: 0.2158 - acc: 0.935 - ETA: 0s - loss: 0.2231 - acc: 0.932 - ETA: 0s - loss: 0.2311 - acc: 0.928 - 2s 3ms/step - loss: 0.2307 - acc: 0.9282 - val_loss: 0.0993 - val_acc: 0.9636\n",
      "Epoch 27/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.2137 - acc: 0.925 - ETA: 1s - loss: 0.2154 - acc: 0.925 - ETA: 0s - loss: 0.2070 - acc: 0.933 - ETA: 0s - loss: 0.2033 - acc: 0.937 - ETA: 0s - loss: 0.2333 - acc: 0.927 - ETA: 0s - loss: 0.2452 - acc: 0.925 - ETA: 0s - loss: 0.2359 - acc: 0.928 - ETA: 0s - loss: 0.2272 - acc: 0.932 - 2s 3ms/step - loss: 0.2268 - acc: 0.9329 - val_loss: 0.1009 - val_acc: 0.9673\n",
      "Epoch 28/30\n",
      "641/641 [==============================] - ETA: 2s - loss: 0.1977 - acc: 0.950 - ETA: 1s - loss: 0.1817 - acc: 0.943 - ETA: 1s - loss: 0.1769 - acc: 0.945 - ETA: 0s - loss: 0.2113 - acc: 0.928 - ETA: 0s - loss: 0.2094 - acc: 0.930 - ETA: 0s - loss: 0.2079 - acc: 0.929 - ETA: 0s - loss: 0.2007 - acc: 0.930 - ETA: 0s - loss: 0.2047 - acc: 0.926 - 2s 3ms/step - loss: 0.2044 - acc: 0.9267 - val_loss: 0.0831 - val_acc: 0.9745\n",
      "Epoch 29/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.1902 - acc: 0.925 - ETA: 1s - loss: 0.2213 - acc: 0.925 - ETA: 0s - loss: 0.1827 - acc: 0.945 - ETA: 0s - loss: 0.1757 - acc: 0.943 - ETA: 0s - loss: 0.1713 - acc: 0.945 - ETA: 0s - loss: 0.1676 - acc: 0.945 - ETA: 0s - loss: 0.1753 - acc: 0.944 - ETA: 0s - loss: 0.1859 - acc: 0.939 - 2s 3ms/step - loss: 0.1858 - acc: 0.9392 - val_loss: 0.1204 - val_acc: 0.9636\n",
      "Epoch 30/30\n",
      "641/641 [==============================] - ETA: 1s - loss: 0.2210 - acc: 0.925 - ETA: 1s - loss: 0.1934 - acc: 0.937 - ETA: 1s - loss: 0.1821 - acc: 0.950 - ETA: 0s - loss: 0.1883 - acc: 0.946 - ETA: 0s - loss: 0.1750 - acc: 0.950 - ETA: 0s - loss: 0.1752 - acc: 0.950 - ETA: 0s - loss: 0.1782 - acc: 0.946 - ETA: 0s - loss: 0.1715 - acc: 0.950 - 2s 3ms/step - loss: 0.1712 - acc: 0.9501 - val_loss: 0.1150 - val_acc: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['finalized_model.sav']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocess import *\n",
    "import keras\n",
    "from sklearn.externals import joblib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "feature_dim_2 = 11\n",
    "# Transform each class into  array of MFCC vectors and save into a file\n",
    "save_data_to_array(max_len=feature_dim_2)\n",
    "\n",
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "# # Feature dimension\n",
    "feature_dim_1 = 20\n",
    "\n",
    "channel = 1\n",
    "epochs = 30\n",
    "batch_size = 80\n",
    "verbose = 1\n",
    "num_classes = 23\n",
    "\n",
    "# Reshaping to perform 2D convolution\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "\n",
    "def get_model(feature_dim_1,feature_dim_2,channel):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "model = get_model(feature_dim_1,feature_dim_2,channel)\n",
    "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))\n",
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
